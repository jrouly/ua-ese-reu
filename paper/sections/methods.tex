\section{Methods}
\label{sec:methods}

% *Find IDEs to study*
%
%   -investigated popular IDEs that utilized a syntactically visual language
%   -IDEs were chosen over a variety of domains for a thourough, overarching
%   comparison
%
% *Where we got variables from / process for their creation*
%
%   -Through observation of the various IDEs, we found the differences and
%   commonalities present within the interfaces that defined either the
%   purpose or the functionality of the IDE
%   -Other variables influenced by other writings (popular features,
%   essential efficiency, visual richness)
%   -These variables were catagories under either audience, chrome, human
%   interface, integration, and language syntax (add definitions from tech
%   report)
%   -Values for the variables were determined by focusing on one variable
%   across each of the IDEs, grouping together the IDEs that integrated
%   similar functionality within that individual variable, and finding a way
%   to define that functionality
%   -(add discussion about each variable and thier values)
%
% *Use of the table to store values*
%
%   -After defining each of the variables and thier possible values, we
%   created a table to store information about each of the IDEs as they
%   relate to the variables
%   -Extra tables created for compound variables (i.e. visual richness,
%   popular features)
%
% *Efficiency - how did we measure it, what were the Use Cases, etc.*
%
%   -Brainstormed three general purpose essential use cases of increasing
%   complexity to test within each IDE
%   -Open a file, create an element, create and link two elements/output a
%   string/output an integer/translate a point
%   -Defined every step for each use case
%   -Worked through each use case for every IDE
%   -Made note of which steps contributed to mental load and the number of
%   physical user actions for each use case
%   -Determined the third and most complex use case to be most representative
%   of the IDEs' efficiency
%   -Final value calculated by dividing the number of mental load
%   steps/physical user actions by the number of steps in the use case and
%   subtracting that value by 1
%
% *Mechanical Turk*
%
%   -Designed a survey in which MTurk users would look at screenshots of the
%   IDEs and rate on a scale of 1 to 5 how "cluttered" they determined the
%   screenshot to be
%   -Provided a formal definition of visual clutter as a reference and
%   guideline for the workers to base thier decisions off of
%   -Took three screenshots each of the IDEs at various levels of use to
%   balance varying amounts of clutter within one IDE
%   -Grayed out the workspace on each screenshot to prevent any model
%   complexity from interfering with the users' rating
%   -Limited each screenshot to 5 unique workers in order to prevent
%   duplicity and collect enough usable data
%   -Calculated worker average for each screenshot and sorted them within
%   their respective IDE by this value
%   -Calculated the average over the screenshots for each IDE and used this
%   as the final value
%
% *How did we score IDEs / how did we determine scoring metrics*
%   -For each nominal or boolean variable, we used our experience with the 25
%   IDEs to justify which values were beneficial or somewhat beneficial to
%   the IDE, which detracted from its use, and which did not affect it either
%   way
%   -For each interval variable, we set thresholds based on collected values 
%   -The scores of thes values were weighed against eachother within each IDE
%   to produce the survey of the suitability and usability of various visual
%   integrated development enviornments
